"""
ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§çµ±åˆãƒ†ã‚¹ãƒˆ

Issue #53 ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾å¿œ: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ã‚’æ¤œè¨¼
"""

import pytest
from typing import List
from unittest.mock import Mock, patch

from models.embedding import EmbeddingResult, EmbeddingBatch, EmbeddingCostCalculator
from services.embeddings import EmbeddingService
from services.text_chunker import TextChunker, ChunkMetadata, TextChunk
from services.claude_llm import ClaudeLLMService
from utils.tokenizer import TokenCounter


class TestTokenCountConsistency:
    """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
    
    def test_token_counter_consistency_across_components(self):
        """å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        test_texts = [
            "çŸ­ã„ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ",
            "ä¸­ç¨‹åº¦ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯è¤‡æ•°ã®æ–‡ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚",
            "é•·ã„ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚" * 50,
            "æ—¥æœ¬èªã¨è‹±èªãŒæ··åœ¨ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚This text contains both Japanese and English.",
            "ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ: @#$%^&*()_+{}|:<>?[]\\;'\",./"
        ]
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
        token_counter = TokenCounter("text-embedding-3-small")
        embedding_service = EmbeddingService("test-api-key", "text-embedding-3-small")
        text_chunker = TextChunker()
        claude_service = ClaudeLLMService("test-api-key")
        cost_calculator = EmbeddingCostCalculator()
        
        for text in test_texts:
            # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            base_count = token_counter.count_tokens(text)
            embedding_service_count = embedding_service.token_counter.count_tokens(text)
            chunker_count = text_chunker.count_tokens(text)
            
            # ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§åŒã˜çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert base_count == embedding_service_count, f"EmbeddingServiceã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸ä¸€è‡´: {base_count} != {embedding_service_count}"
            assert base_count == chunker_count, f"TextChunkerã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸ä¸€è‡´: {base_count} != {chunker_count}"
            
            # EmbeddingResultã§ã‚‚åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒè¨˜éŒ²ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            embedding_result = EmbeddingResult(
                text=text,
                embedding=[0.1] * 1536,
                token_count=base_count,
                model="text-embedding-3-small"
            )
            assert embedding_result.token_count == base_count
    
    def test_embedding_service_token_count_accuracy(self):
        """EmbeddingServiceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        service = EmbeddingService("test-api-key", "text-embedding-3-small")
        token_counter = TokenCounter("text-embedding-3-small")
        
        test_text = "ã“ã‚Œã¯ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚æ­£ç¢ºæ€§ã‚’ç¢ºèªã—ã¾ã™ã€‚"
        
        # å˜ä¸€åŸ‹ã‚è¾¼ã¿ä½œæˆæ™‚ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        result = service.create_embedding(test_text)
        expected_count = token_counter.count_tokens(test_text)
        
        assert result.token_count == expected_count
        
        # ãƒãƒƒãƒåŸ‹ã‚è¾¼ã¿ä½œæˆæ™‚ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        test_texts = [
            "ãƒ†ã‚­ã‚¹ãƒˆ1ã§ã™ã€‚",
            "ãƒ†ã‚­ã‚¹ãƒˆ2ã¯ã‚‚ã†å°‘ã—é•·ããªã‚Šã¾ã™ã€‚",
            "ãƒ†ã‚­ã‚¹ãƒˆ3ã¯ã•ã‚‰ã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã‚Œã¯è¤‡æ•°ã®æ–‡ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"
        ]
        
        batch_result = service.create_batch_embeddings(test_texts)
        
        for i, result in enumerate(batch_result.results):
            expected_count = token_counter.count_tokens(test_texts[i])
            assert result.token_count == expected_count, f"ãƒãƒƒãƒ{i}ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸ä¸€è‡´"
    
    def test_text_chunker_token_count_consistency(self):
        """TextChunkerã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆãŒä¸€è²«ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        chunker = TextChunker(chunk_size=100, overlap_ratio=0.1)
        token_counter = TokenCounter("text-embedding-3-small")
        
        # ãƒ¢ãƒƒã‚¯Documentã¨Pageã‚’ä½œæˆ
        mock_document = Mock()
        mock_document.filename = "test.pdf"
        mock_document.document_id = "test-doc-id"
        mock_document.metadata = {"document_structure": Mock(sections=[])}
        
        mock_page = Mock()
        mock_page.page_number = 1
        mock_page.text_blocks = [
            Mock(content="ã“ã‚Œã¯æœ€åˆã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚"),
            Mock(content="ã“ã‚Œã¯2ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚"),
            Mock(content="ã“ã‚Œã¯3ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚")
        ]
        
        mock_document.pages = [mock_page]
        
        # spaCyãƒ¢ãƒƒã‚¯ã‚’è¨­å®š
        with patch.object(chunker, 'nlp') as mock_nlp:
            mock_doc = Mock()
            mock_sentences = [
                Mock(text="ã“ã‚Œã¯æœ€åˆã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚"),
                Mock(text="ã“ã‚Œã¯2ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚"),
                Mock(text="ã“ã‚Œã¯3ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚")
            ]
            mock_doc.sents = mock_sentences
            mock_nlp.return_value = mock_doc
            
            chunks = chunker.split_text_into_chunks(mock_document)
            
            # å„ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            for chunk in chunks:
                expected_count = token_counter.count_tokens(chunk.content)
                assert chunk.metadata.token_count == expected_count
    
    def test_claude_service_token_count_accuracy(self):
        """ClaudeServiceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        service = ClaudeLLMService("test-api-key")
        token_counter = TokenCounter()
        
        query = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§ã™ã€‚"
        context_chunks = [
            "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯1ã§ã™ã€‚",
            "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯2ã¯ã‚‚ã†å°‘ã—é•·ã„ã§ã™ã€‚"
        ]
        
        result = service.generate_response(query, context_chunks)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆæ™‚ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        expected_input_tokens = token_counter.count_tokens(service._build_user_prompt(query, context_chunks))
        expected_output_tokens = token_counter.count_tokens(result.content)
        
        assert result.usage["input_tokens"] == expected_input_tokens
        assert result.usage["output_tokens"] == expected_output_tokens
    
    def test_cost_calculation_consistency(self):
        """ã‚³ã‚¹ãƒˆè¨ˆç®—ã®ä¸€è²«æ€§ã‚’ç¢ºèª"""
        calculator = EmbeddingCostCalculator()
        token_counter = TokenCounter("text-embedding-3-small")
        
        test_texts = [
            "çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ",
            "ä¸­ç¨‹åº¦ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
            "é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã€‚" * 100
        ]
        
        # æ‰‹å‹•ã§ã®ã‚³ã‚¹ãƒˆè¨ˆç®—
        total_manual_cost = 0.0
        for text in test_texts:
            token_count = token_counter.count_tokens(text)
            cost = calculator.calculate_cost(token_count, "text-embedding-3-small")
            total_manual_cost += cost
        
        # estimate_batch_costã§ã®è¨ˆç®—
        batch_cost_estimate = calculator.estimate_batch_cost(test_texts, "text-embedding-3-small")
        
        # ä¸¡æ–¹ã®è¨ˆç®—çµæœãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆå°æ•°ç‚¹èª¤å·®ã‚’è€ƒæ…®ï¼‰
        assert abs(total_manual_cost - batch_cost_estimate["estimated_cost_usd"]) < 0.0001
    
    def test_embedding_batch_token_consistency(self):
        """EmbeddingBatchã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸€è²«ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        token_counter = TokenCounter("text-embedding-3-small")
        
        test_texts = [
            "ãƒãƒƒãƒãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ1",
            "ãƒãƒƒãƒãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ2",
            "ãƒãƒƒãƒãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ3"
        ]
        
        # EmbeddingResultã‚’ä½œæˆ
        results = []
        expected_total_tokens = 0
        
        for text in test_texts:
            token_count = token_counter.count_tokens(text)
            expected_total_tokens += token_count
            
            result = EmbeddingResult(
                text=text,
                embedding=[0.1] * 1536,
                token_count=token_count,
                model="text-embedding-3-small"
            )
            results.append(result)
        
        # EmbeddingBatchä½œæˆ
        batch = EmbeddingBatch(results)
        
        # ãƒãƒƒãƒã®åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert batch.total_tokens == expected_total_tokens
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—ãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        stats = batch.get_statistics()
        assert stats["total_tokens"] == expected_total_tokens
        assert stats["count"] == len(test_texts)
    
    def test_token_count_model_consistency(self):
        """ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ã‚’ç¢ºèª"""
        models = ["text-embedding-3-small", "text-embedding-3-large"]
        test_text = "ãƒ¢ãƒ‡ãƒ«é–“ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"
        
        # åŒã˜ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆcl100k_baseï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã¯
        # åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        token_counts = {}
        
        for model in models:
            counter = TokenCounter(model)
            token_counts[model] = counter.count_tokens(test_text)
        
        # text-embedding-3ç³»ã¯åŒã˜ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚åŒã˜çµæœ
        assert token_counts["text-embedding-3-small"] == token_counts["text-embedding-3-large"]
    
    def test_large_text_token_consistency(self):
        """å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        # Streamlit Cloudåˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸå¤§ããªãƒ†ã‚­ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
        large_text = "å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆãƒ†ã‚¹ãƒˆã§ã™ã€‚" * 1000
        
        token_counter = TokenCounter("text-embedding-3-small")
        embedding_service = EmbeddingService("test-api-key", "text-embedding-3-small")
        text_chunker = TextChunker()
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§åŒã˜çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        base_count = token_counter.count_tokens(large_text)
        service_count = embedding_service.token_counter.count_tokens(large_text)
        chunker_count = text_chunker.count_tokens(large_text)
        
        assert base_count == service_count
        assert base_count == chunker_count
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚‚ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ï¼‰
        assert base_count > 0
        assert isinstance(base_count, int)


class TestTokenCountEdgeCases:
    """ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    def test_empty_text_consistency(self):
        """ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã§ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        token_counter = TokenCounter()
        embedding_service = EmbeddingService("test-api-key")
        text_chunker = TextChunker()
        
        empty_texts = ["", "   ", "\n", "\t", "   \n\t   "]
        
        for empty_text in empty_texts:
            base_count = token_counter.count_tokens(empty_text)
            service_count = embedding_service.token_counter.count_tokens(empty_text)
            chunker_count = text_chunker.count_tokens(empty_text)
            
            # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã¯å…¨ã¦0ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
            assert base_count == 0
            assert service_count == 0
            assert chunker_count == 0
    
    def test_special_characters_consistency(self):
        """ç‰¹æ®Šæ–‡å­—ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        special_texts = [
            "ğŸš€ğŸ¯ğŸ“ŠğŸ’¡",  # çµµæ–‡å­—
            "â‘ â‘¡â‘¢â‘£â‘¤",   # ä¸¸æ•°å­—
            "Î± Î² Î³ Î´ Îµ",  # ã‚®ãƒªã‚·ãƒ£æ–‡å­—
            "ä¸­æ–‡ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",  # å¤šè¨€èª
            "HTML<tag>content</tag>",  # ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—
            "JSON{\"key\": \"value\"}",  # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
        ]
        
        token_counter = TokenCounter()
        embedding_service = EmbeddingService("test-api-key")
        
        for text in special_texts:
            base_count = token_counter.count_tokens(text)
            service_count = embedding_service.token_counter.count_tokens(text)
            
            assert base_count == service_count
            assert base_count > 0  # ç‰¹æ®Šæ–‡å­—ã§ã‚‚ä½•ã‚‰ã‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚Œã‚‹


# çµ±åˆãƒ†ã‚¹ãƒˆç”¨ã®ãƒãƒ¼ã‚«ãƒ¼
pytestmark = pytest.mark.integration